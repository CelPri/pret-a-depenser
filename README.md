# ğŸ“Š Projet 8 - SystÃ¨me de Scoring de CrÃ©dit

> **PrÃ©diction automatisÃ©e de l'accord/refus de crÃ©dits avec API REST et monitoring en temps rÃ©el**

---

## ğŸ“‹ Table des matiÃ¨res

- [Vue d'ensemble](#vue-densemble)
- [Architecture du projet](#architecture-du-projet)
- [Technologies utilisÃ©es](#technologies-utilisÃ©es)
- [Installation](#installation)
- [Configuration](#configuration)
- [Utilisation](#utilisation)
- [Structure des donnÃ©es](#structure-des-donnÃ©es)
- [API REST](#api-rest)
- [Monitoring et logs](#monitoring-et-logs)
- [DÃ©ploiement](#dÃ©ploiement)
- [Tests](#tests)
- [Documentation supplÃ©mentaire](#documentation-supplÃ©mentaire)
- [Troubleshooting](#troubleshooting)

---

## ğŸ¯ Vue d'ensemble

Ce projet implÃ©mente un **systÃ¨me complet de scoring de crÃ©dit** permettant de prÃ©dire l'accord ou le refus d'un prÃªt bancaire pour un client. Le systÃ¨me combine :

âœ… **ModÃ©lisation ML avancÃ©e** avec LightGBM
âœ… **API REST moderne** avec FastAPI
âœ… **Interface de monitoring** avec Streamlit
âœ… **Versioning du modÃ¨le** via MLflow et Hugging Face Hub
âœ… **Containerisation** avec Docker
âœ… **Tests automatisÃ©s** avec pytest

**Objectif principal** : PrÃ©dire si un client pourra rembourser son prÃªt en fonction de ses caractÃ©ristiques financiÃ¨res et personnelles.

---

## ğŸ—ï¸ Architecture du projet

### Vue d'ensemble architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      UTILISATEURS                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                          â”‚
         â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
         â”‚ Streamlit  â”‚            â”‚   FastAPI   â”‚
         â”‚ Dashboard  â”‚            â”‚  API REST   â”‚
         â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
               â”‚                          â”‚
         â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
         â”‚     ModÃ¨le LightGBM (en production)   â”‚
         â”‚         (version contrÃ´lÃ©e)          â”‚
         â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
               â”‚                          â”‚
         â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
         â”‚ MLflow DB  â”‚            â”‚  Hugging    â”‚
         â”‚ (versioning)â”‚            â”‚  Face Hub   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### RÃ©pertoires clÃ©s

```
projet8/
â”œâ”€â”€ src/                        # Code source principal
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ main.py            # API FastAPI (endpoints)
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â””â”€â”€ model.py           # Chargement du modÃ¨le
â”‚   â””â”€â”€ inference/             # Module infÃ©rence
â”œâ”€â”€ notebooks/                 # Notebooks Jupyter
â”‚   â”œâ”€â”€ 01_eda.ipynb          # Analyse exploratoire des donnÃ©es
â”‚   â”œâ”€â”€ 02_fusion.ipynb       # Fusion et prÃ©paration des donnÃ©es
â”‚   â””â”€â”€ 03_modelisation.ipynb # EntraÃ®nement du modÃ¨le
â”œâ”€â”€ Data/                      # DonnÃ©es brutes et traitÃ©es
â”‚   â”œâ”€â”€ features_clients.csv   # CaractÃ©ristiques clients
â”‚   â””â”€â”€ Processed/
â”‚       â””â”€â”€ application_train_fused.csv  # DonnÃ©es fusionnÃ©es
â”œâ”€â”€ app/
â”‚   â””â”€â”€ model.joblib           # ModÃ¨le sÃ©rialisÃ©
â”œâ”€â”€ tests/                     # Tests automatisÃ©s
â”œâ”€â”€ monitoring/               # Monitoring et analyse
â”‚   â””â”€â”€ (contient les scripts de monitoring)
â”œâ”€â”€ mlruns/                   # Artefacts MLflow
â”‚   â””â”€â”€ (versioning du modÃ¨le)
â”œâ”€â”€ docker/                   # Configuration Docker
â”œâ”€â”€ scripts/                  # Scripts utilitaires
â”‚   â””â”€â”€ export_model.py      # Export du modÃ¨le
â”œâ”€â”€ streamlit_app.py          # Dashboard de monitoring Streamlit
â”œâ”€â”€ drift_analysis.py         # Analyse de data drift
â”œâ”€â”€ analyze_logs.py          # Analyse des logs API
â”œâ”€â”€ debug_model.py            # Script de dÃ©bogage
â”œâ”€â”€ Dockerfile                # Configuration Docker
â”œâ”€â”€ mlflow.db                 # Base de donnÃ©es MLflow
â”œâ”€â”€ api_logs.jsonl           # Logs des prÃ©dictions API
â”œâ”€â”€ data_drift_report.html   # Rapport de drift Evidently
â””â”€â”€ requirements.txt          # DÃ©pendances Python
```

---

## ğŸ› ï¸ Technologies utilisÃ©es

| CatÃ©gorie | Technologies |
|-----------|-------------|
| **ML/Data Science** | LightGBM, scikit-learn, pandas, numpy |
| **Web Backend** | FastAPI, Uvicorn |
| **Monitoring** | Streamlit, MLflow, Evidently.ai |
| **Data Drift Detection** | Evidently.ai (rapports HTML) |
| **Versioning ModÃ¨le** | MLflow, Hugging Face Hub |
| **Testing** | pytest, httpx |
| **Containerisation** | Docker |
| **Python Version** | 3.12 (compatible 3.9+) |

---

## ğŸ“¦ Installation

### 1. Cloner le repositorysion

```bash
git clone <repository-url>
cd projet8
```

### 2. CrÃ©er un environnement virtuel

```bash
# Windows
python -m venv projet8
projet8\Scripts\activate

# MacOS/Linux
python -m venv projet8
source projet8/bin/activate
```

### 3. Installer les dÃ©pendances

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

### 4. VÃ©rifier l'installation

```bash
python debug_model.py
```

---

## âš™ï¸ Configuration

### Variables d'environnement requises

CrÃ©ez un fichier `.env` Ã  la racine du projet :

```bash
# Hugging Face Hub (optionnel, pour le tÃ©lÃ©chargement du modÃ¨le)
HF_TOKEN=hf_votre_token_huggingface

# MLflow (optionnel)
MLFLOW_TRACKING_URI=sqlite:///mlflow.db
```

### Obtenir votre token HF

1. CrÃ©ez un compte sur [huggingface.co](https://huggingface.co)
2. Allez dans Settings â†’ Access Tokens
3. CrÃ©ez un nouveau token
4. Collez-le dans votre `.env`

### Chargement du modÃ¨le

Le modÃ¨le se charge automatiquement de 3 sources (dans cet ordre) :

1. **Hugging Face Hub** : `PCelia/credit-scoring-model`
2. **MLflow local** : `models:/CreditScoring_LightGBM/Production`
3. **Fichier local** : `app/model.joblib`

---

## ğŸš€ Utilisation

### Lancer l'API

```bash
# Mode dÃ©veloppement
uvicorn src.api.main:app --reload

# Mode production
uvicorn src.api.main:app --host 0.0.0.0 --port 8000
```

L'API sera accessible sur `http://localhost:8000`

### AccÃ©der Ã  la documentation interactive

- **Swagger UI** : http://localhost:8000/docs
- **ReDoc** : http://localhost:8000/redoc

### Lancer le tableau de bord Streamlit

```bash
streamlit run streamlit_app.py
```

Accessible sur `http://localhost:8501`

---

## ğŸ“Š Structure des donnÃ©es

### Fichiers de donnÃ©es

| Fichier | Description | Taille |
|---------|------------|--------|
| `features_clients.csv` | CaractÃ©ristiques brutes des clients | Variable |
| `application_train_fused.csv` | DonnÃ©es d'entraÃ®nement fusionnÃ©es et nettoyÃ©es | Variable |

### Colonnes principales

Les donnÃ©es contiennent des informations sur :
- **IdentitÃ©** : SK_ID_CURR (identifiant client)
- **DonnÃ©es personnelles** : age, genre, situation familiale
- **DonnÃ©es financiÃ¨res** : revenus, dettes existantes, historique de crÃ©dit
- **DonnÃ©es professionnelles** : secteur, durÃ©e d'emploi

### Pipeline de donnÃ©es

```
DonnÃ©es brutes
    â†“
01_eda.ipynb (Exploration)
    â†“
02_fusion.ipynb (Fusion et nettoyage)
    â†“
DonnÃ©es traitÃ©es
    â†“
03_modelisation.ipynb (EntraÃ®nement LightGBM)
    â†“
ModÃ¨le ML exportÃ©
```

---

## ğŸ”Œ API REST

### Endpoints disponibles

#### 1. **PrÃ©diction (POST)**

```bash
POST /predict
Content-Type: application/json

{
  "sk_id_curr": 100001
}
```

**RÃ©ponse succÃ¨s (200)**
```json
{
  "sk_id_curr": 100001,
  "score": 0.73,
  "decision": "ACCORD",
  "probability_refusal": 0.27,
  "probability_approval": 0.73
}
```

**RÃ©ponse erreur (404)**
```json
{
  "detail": "Client not found"
}
```

#### 2. **SantÃ© de l'API (GET)**

```bash
GET /health
```

**RÃ©ponse (200)**
```json
{
  "status": "healthy"
}
```

### Exemplez d'utilisation

#### Avec `curl`

```bash
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d "{\"sk_id_curr\": 100001}"
```

#### Avec Python

```python
import requests

response = requests.post(
    "http://localhost:8000/predict",
    json={"sk_id_curr": 100001}
)
result = response.json()
print(f"Score: {result['score']}")
print(f"DÃ©cision: {result['decision']}")
```

#### Avec `httpx` (async)

```python
import httpx
import asyncio

async def get_prediction():
    async with httpx.AsyncClient() as client:
        response = await client.post(
            "http://localhost:8000/predict",
            json={"sk_id_curr": 100001}
        )
        return response.json()

asyncio.run(get_prediction())
```

### Codes HTTP

| Code | Signification |
|------|---------------|
| 200 | PrÃ©diction rÃ©ussie |
| 404 | Client non trouvÃ© |
| 422 | Format de requÃªte invalide |
| 500 | Erreur serveur |

---

## ğŸ“ˆ Monitoring et logs

### Tableau de bord Streamlit

Lancez le tableau de bord de monitoring :

```bash
streamlit run streamlit_app.py
```

L'application `streamlit_app.py` fournit en temps rÃ©el :

- ğŸ“Š **Latence API** : MÃ©trique et graphique des temps de rÃ©ponse
- ğŸ“‰ **Distribution des scores** : Analyse des dÃ©cisions de crÃ©dit
- ğŸ’¾ **Historique complet** : Tous les appels enregistrÃ©s en temps rÃ©el
- ğŸ” **Data Drift** : Surveillance de la dÃ©rive des donnÃ©es avec Evidently
- ğŸ¯ **Statut du systÃ¨me** : CPU et mÃ©moire en temps rÃ©el

Accessible sur http://localhost:8501

### Analyse du Data Drift

**Evidently.ai** est intÃ©grÃ© pour dÃ©tecter la dÃ©rive des donnÃ©es en temps rÃ©el :

#### GÃ©nÃ©ration de rapports

```bash
# GÃ©nÃ©rer un rapport de drift
python monitoring/drift_analysis.py
```

Cela gÃ©nÃ¨re `data_drift_report.html` avec :
- âœ… DÃ©tection automatique des dÃ©rives
- âœ… Comparaison des distributions (rÃ©fÃ©rence vs. donnÃ©es actuelles)
- âœ… Alertes sur les changements significatifs
- âœ… Graphiques dÃ©taillÃ©s par feature

#### Analyse interactive

Vous pouvez aussi utiliser le notebook interactif :

```bash
jupyter notebook data_drift_analysis.ipynb
```

Ce notebook permet de :
- Explorer les dÃ©rives en temps rÃ©el
- Configurer les seuils d'alerte personnalisÃ©s
- GÃ©nÃ©rer des rapports HTML automatiques
- Visualiser les changements de distribution

### Format des logs

Les logs sont stockÃ©s dans `api_logs.jsonl` (JSON Lines) :

```json
{"timestamp": "2024-02-08T10:30:45", "sk_id_curr": 100001, "score": 0.73, "total_time": 0.045}
{"timestamp": "2024-02-08T10:30:50", "sk_id_curr": 100002, "score": 0.42, "total_time": 0.038}
```

### Visualiser les logs

```bash
# Voir les 10 derniÃ¨res prÃ©dictions
tail -10 api_logs.jsonl

# Convertir en CSV pour analyse
python analyze_logs.py
```

### MLflow Tracking

Les expÃ©riences de modÃ©lisation sont tracÃ©es avec MLflow :

```bash
# Consulter l'historique des modÃ¨les
mlflow ui

# AccÃ©der Ã  http://localhost:5000
```

---

## ğŸ³ DÃ©ploiement

### Avec Docker (recommandÃ©)

#### 1. Construire l'image

```bash
docker build -t credit-scoring:latest .
```

#### 2. ExÃ©cuter le conteneur

```bash
# Mode dÃ©veloppement avec volumes
docker run -p 8000:7860 \
  -e HF_TOKEN=hf_votre_token \
  -v $(pwd)/Data:/app/Data \
  -v $(pwd)/api_logs.jsonl:/app/api_logs.jsonl \
  credit-scoring:latest

# Mode production
docker run -d -p 8000:7860 \
  --name credit-api \
  -e HF_TOKEN=hf_votre_token \
  credit-scoring:latest
```

#### 3. AccÃ©der Ã  l'API

```
http://localhost:8000
```

#### 4. Monitorer le conteneur

```bash
# Voir les logs
docker logs credit-api

# AccÃ©der Ã  Streamlit (dans le conteneur)
docker exec credit-api streamlit run streamlit_app.py --server.port 8501
```

### Docker Compose

```yaml
version: '3.8'

services:
  api:
    build: .
    ports:
      - "8000:7860"
    environment:
      - HF_TOKEN=${HF_TOKEN}
    volumes:
      - ./Data:/app/Data
      - ./api_logs.jsonl:/app/api_logs.jsonl
```

Lancer avec :
```bash
docker-compose up
```

### DÃ©ploiement sur Hugging Face Spaces

Ce projet est configurÃ© pour Hugging Face Spaces (voir `README_HF.md`) :

```yaml
title: Pret A Depenser
emoji: ğŸ“‰
colorFrom: green
colorTo: indigo
sdk: docker
```

---

## ğŸ§ª Tests

### Structure des tests

```
tests/
â”œâ”€â”€ unit/                    # Tests unitaires
â”‚   â”œâ”€â”€ test_model_unit.py          # Tests du modÃ¨le
â”‚   â”œâ”€â”€ test_preprocessing.py       # Tests du prÃ©traitement
â”‚   â”œâ”€â”€ test_input_validation.py    # Validation des entrÃ©es
â”‚   â””â”€â”€ test_model_loading.py       # Chargement du modÃ¨le
â”œâ”€â”€ fonctionnal/             # Tests fonctionnels/intÃ©gration
â”‚   â”œâ”€â”€ test_api.py                 # Tests de l'API REST
â”‚   â”œâ”€â”€ test_response_schema.py     # SchÃ©ma des rÃ©ponses
â”‚   â”œâ”€â”€ test_error_handling.py      # Gestion des erreurs
â”‚   â””â”€â”€ test_latency.py             # Latence des rÃ©ponses
â””â”€â”€ conftest.py              # Configurations pytest
```

### Lancer les tests

```bash
# Tous les tests
pytest

# Avec verbose
pytest -v

# Coverage (couverture de code)
pytest --cov=src

# Seulement tests unitaires
pytest tests/unit/

# Seulement tests fonctionnels
pytest tests/fonctionnal/

# Test spÃ©cifique
pytest tests/unit/test_model_unit.py::test_model_prediction -v
```

### Exemples de tests

```bash
# Tests unitaires du modÃ¨le
pytest tests/unit/test_model_unit.py -v

# Tests API
pytest tests/fonctionnal/test_api.py -v

# Tests de latence
pytest tests/fonctionnal/test_latency.py -v

# Rapport coverage dÃ©taillÃ©
pytest --cov=src --cov-report=html
```

### Ajouter vos propres tests

```python
# tests/unit/test_mon_test.py

import pytest
from src.model.model import load_model

def test_model_loading():
    """Teste le chargement du modÃ¨le"""
    model = load_model()
    assert model is not None

def test_prediction_shape():
    """Teste que la prÃ©diction a la bonne forme"""
    model = load_model()
    predictions = model.predict([[1, 2, 3, 4, 5]])
    assert predictions.shape[0] == 1
```

---

## ğŸ“š Documentation supplÃ©mentaire

### Notebooks Jupyter

| Notebook | Description |
|----------|-------------|
| [01_eda.ipynb](notebooks/01_eda.ipynb) | Analyse exploratoire des donnÃ©es (EDA) |
| [02_fusion.ipynb](notebooks/02_fusion.ipynb) | Fusion de sources et prÃ©paration |
| [03_modelisation.ipynb](notebooks/03_modelisation.ipynb) | EntraÃ®nement et validation du modÃ¨le || [data_drift_analysis.ipynb](data_drift_analysis.ipynb) | **NOUVEAU** : Analyse interactive du data drift avec Evidently |
### Scripts utilitaires

```bash
# Exporter le modÃ¨le depuis MLflow
python scripts/export_model.py

# DÃ©boguer et tester le modÃ¨le
python debug_model.py

# Analyser les logs API en dÃ©tail
python monitoring/analyze_logs.py

# Analyser la dÃ©rive des donnÃ©es (Data Drift)
python monitoring/drift_analysis.py
```

### Chaining des outils

Pipeline complet de monitoring :

```bash
# 1. Lancer l'API
uvicorn src.api.main:app --reload &

# 2. GÃ©nÃ©rer quelques prÃ©dictions
for i in {1..10}; do
  curl -X POST "http://localhost:8000/predict" \
    -H "Content-Type: application/json" \
    -d "{\"sk_id_curr\": $((100000 + i))}"
done

# 3. Analyser les logs
python monitoring/analyze_logs.py

# 4. GÃ©nÃ©rer le rapport de drift
python monitoring/drift_analysis.py

# 5. Consulter le tableau de bord
streamlit run streamlit_app.py
```

### Ressources externes

- ğŸ“– [Documentation FastAPI](https://fastapi.tiangolo.com)
- ğŸ“– [Documentation LightGBM](https://lightgbm.readthedocs.io)
- ğŸ“– [Documentation Streamlit](https://docs.streamlit.io)
- ğŸ“– [Documentation MLflow](https://mlflow.org/docs)
- ğŸ“– [Hub Hugging Face](https://huggingface.co)

---

## ğŸ”§ Troubleshooting

### ProblÃ¨me : ModÃ¨le non trouvÃ©

**Erreur**
```
FileNotFoundError: Impossible de charger le modÃ¨le (ni HF Hub, ni MLflow)
```

**Solutions**
```bash
# 1. VÃ©rifier le chemin local
ls app/model.joblib

# 2. VÃ©rifier MLflow
python -c "import mlflow; print(mlflow.get_tracking_uri())"

# 3. DÃ©finir le token HF
export HF_TOKEN=your_token
# ou dans .env
echo "HF_TOKEN=your_token" > .env
```

### ProblÃ¨me : Token HF expirÃ©

**Solution**
```bash
# CrÃ©er un nouveau token sur https://huggingface.co/settings/tokens
# Mettre Ã  jour le fichier .env
nano .env  # ou edit .env
```

### ProblÃ¨me : Port dÃ©jÃ  utilisÃ©

**Erreur**
```
Address already in use: ('0.0.0.0', 8000)
```

**Solution**
```bash
# Changer le port
uvicorn src.api.main:app --port 8001

# Ou tuer le processus existant
# Windows
netstat -ano | findstr :8000
taskkill /PID <PID> /F

# Linux/Mac
lsof -ti:8000 | xargs kill -9
```

### ProblÃ¨me : Erreur LightGBM Windows

**Erreur**
```
ImportError: cannot open shared object file: No such file or directory
```

**Solution**
```bash
# RÃ©installer LightGBM
pip uninstall lightgbm -y
pip install lightgbm --force-reinstall
```

### ProblÃ¨me : Streamlit ne se lance pas

**Solution**
```bash
# VÃ©rifier les permissions
streamlit run streamlit_app.py --logger.level=debug

# RÃ©installer Streamlit
pip uninstall streamlit -y
pip install streamlit
```

---

## ğŸ‘¥ Auteurs et contribution

Ce projet a Ã©tÃ© dÃ©veloppÃ© dans le cadre d'une formation en Machine Learning.

### Structure Git

```
main                    # Branche principale (production)
â”œâ”€â”€ develop            # Branche de dÃ©veloppement
â””â”€â”€ feature/*          # Branches de fonctionnalitÃ©s
```

### Contribuer

1. CrÃ©er une branche `feature/ma-feature`
2. Faire vos commits
3. Pousser vers le repo
4. Ouvrir une Pull Request

---

## ğŸ“„ Licence

Ce projet est Ã  usage Ã©ducatif.

---

## ğŸ“ Support

Pour toute question ou problÃ¨me :
1. Consulter la section [Troubleshooting](#troubleshooting)
2. VÃ©rifier les logs : `api_logs.jsonl`
3. Lancer les tests : `pytest -v`
4. Ouvrir une issue avec les dÃ©tails

---

## âœ¨ Roadmap future

- [ ] âœ… **Data Drift Detection** (Evidently.ai) - COMPLÃ‰TÃ‰
- [ ] âœ… **Monitoring Dashboard** (Streamlit) - COMPLÃ‰TÃ‰
- [ ] âœ… **API Logging & Analytics** - COMPLÃ‰TÃ‰
- [ ] Ajouter explication des prÃ©dictions (SHAP/LIME)
- [ ] Interface web avancÃ©e (React/Next.js)
- [ ] Alertes email sur data drift
- [ ] AmÃ©liorer le monitoring (Prometheus + Grafana)
- [ ] DÃ©ploiement Kubernetes
- [ ] Tests de performance E2E
- [ ] CI/CD pipeline GitHub Actions

---

---

## ğŸ“ NouveautÃ©s rÃ©centes

### v1.1.0 (FÃ©vrier 2026)

âœ¨ **Nouvelles fonctionnalitÃ©s** :
- ğŸ” DÃ©tection automatique du **Data Drift** avec Evidently.ai
- ğŸ“Š Tableau de bord **Streamlit** pour le monitoring en temps rÃ©el
- ğŸ“ˆ Analyse des logs API avec **psutil** (CPU, mÃ©moire)
- ğŸ““ Notebook interactif pour l'analyse du drift
- ğŸš€ Support Docker amÃ©liorÃ© avec volumes persistants

ğŸ› **Corrections** :
- AmÃ©lioration du chargement du modÃ¨le (fallback multi-sources)
- Meilleure gestion des erreurs API
- Optimisation des performances

---

**DerniÃ¨re mise Ã  jour** : 15 FÃ©vrier 2026