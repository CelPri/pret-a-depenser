# ğŸ“Š Projet 8 - SystÃ¨me de Scoring de CrÃ©dit

> **PrÃ©diction automatisÃ©e de l'accord/refus de crÃ©dits avec API REST et monitoring en temps rÃ©el**

---

## ğŸ“‹ Table des matiÃ¨res

- [Vue d'ensemble](#vue-densemble)
- [Architecture du projet](#architecture-du-projet)
- [Technologies utilisÃ©es](#technologies-utilisÃ©es)
- [Installation](#installation)
- [Configuration](#configuration)
- [Utilisation](#utilisation)
- [Structure des donnÃ©es](#structure-des-donnÃ©es)
- [API REST](#api-rest)
- [Monitoring et logs](#monitoring-et-logs)
- [DÃ©ploiement](#dÃ©ploiement)
- [Tests](#tests)
- [Documentation supplÃ©mentaire](#documentation-supplÃ©mentaire)
- [Troubleshooting](#troubleshooting)

---

## ğŸ¯ Vue d'ensemble

Ce projet implÃ©mente un **systÃ¨me complet de scoring de crÃ©dit** permettant de prÃ©dire l'accord ou le refus d'un prÃªt bancaire pour un client. Le systÃ¨me combine :

âœ… **ModÃ©lisation ML avancÃ©e** avec LightGBM
âœ… **API REST moderne** avec FastAPI
âœ… **Interface de monitoring** avec Streamlit
âœ… **Versioning du modÃ¨le** via MLflow et Hugging Face Hub
âœ… **Containerisation** avec Docker
âœ… **Tests automatisÃ©s** avec pytest

**Objectif principal** : PrÃ©dire si un client pourra rembourser son prÃªt en fonction de ses caractÃ©ristiques financiÃ¨res et personnelles.

---

## ğŸ—ï¸ Architecture du projet

### Vue d'ensemble architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      UTILISATEURS                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                          â”‚
         â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
         â”‚ Streamlit  â”‚            â”‚   FastAPI   â”‚
         â”‚ Dashboard  â”‚            â”‚  API REST   â”‚
         â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
               â”‚                          â”‚
         â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
         â”‚     ModÃ¨le LightGBM (en production)   â”‚
         â”‚         (version contrÃ´lÃ©e)          â”‚
         â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
               â”‚                          â”‚
         â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
         â”‚ MLflow DB  â”‚            â”‚  Hugging    â”‚
         â”‚ (versioning)â”‚            â”‚  Face Hub   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### RÃ©pertoires clÃ©s

```
projet8/
â”œâ”€â”€ src/                        # Code source principal
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ main.py            # API FastAPI (endpoints)
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â””â”€â”€ model.py           # Chargement du modÃ¨le
â”‚   â””â”€â”€ inference/             # Module infÃ©rence
â”œâ”€â”€ notebooks/                 # Notebooks Jupyter
â”‚   â”œâ”€â”€ 01_eda.ipynb          # Analyse exploratoire des donnÃ©es
â”‚   â”œâ”€â”€ 02_fusion.ipynb       # Fusion et prÃ©paration des donnÃ©es
â”‚   â””â”€â”€ 03_modelisation.ipynb # EntraÃ®nement du modÃ¨le
â”œâ”€â”€ Data/                      # DonnÃ©es brutes et traitÃ©es
â”‚   â”œâ”€â”€ features_clients.csv   # CaractÃ©ristiques clients
â”‚   â””â”€â”€ Processed/
â”‚       â””â”€â”€ application_train_fused.csv  # DonnÃ©es fusionnÃ©es
â”œâ”€â”€ app/
â”‚   â””â”€â”€ model.joblib           # ModÃ¨le sÃ©rialisÃ©
â”œâ”€â”€ tests/                     # Tests unitaires
â”‚   â””â”€â”€ test_api.py           # Tests de l'API
â”œâ”€â”€ docker/                    # Configuration Docker
â”œâ”€â”€ scripts/                   # Scripts utilitaires
â”‚   â””â”€â”€ export_model.py       # Export du modÃ¨le
â”œâ”€â”€ streamlit_app.py           # Application de monitoring
â”œâ”€â”€ debug_model.py             # Script de dÃ©bogage
â”œâ”€â”€ Dockerfile                 # Configuration Docker
â””â”€â”€ requirements.txt           # DÃ©pendances Python
```

---

## ğŸ› ï¸ Technologies utilisÃ©es

| CatÃ©gorie | Technologies |
|-----------|-------------|
| **ML/Data Science** | LightGBM, scikit-learn, pandas, numpy |
| **Web Backend** | FastAPI, Uvicorn |
| **Monitoring** | Streamlit, MLflow |
| **Versioning ModÃ¨le** | MLflow, Hugging Face Hub |
| **Testing** | pytest, httpx |
| **Containerisation** | Docker |
| **Python Version** | 3.9+ (3.12 dans l'environnement) |

---

## ğŸ“¦ Installation

### 1. Cloner le repositorysion

```bash
git clone <repository-url>
cd projet8
```

### 2. CrÃ©er un environnement virtuel

```bash
# Windows
python -m venv projet8
projet8\Scripts\activate

# MacOS/Linux
python -m venv projet8
source projet8/bin/activate
```

### 3. Installer les dÃ©pendances

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

### 4. VÃ©rifier l'installation

```bash
python debug_model.py
```

---

## âš™ï¸ Configuration

### Variables d'environnement requises

CrÃ©ez un fichier `.env` Ã  la racine du projet :

```bash
# Hugging Face Hub (optionnel, pour le tÃ©lÃ©chargement du modÃ¨le)
HF_TOKEN=hf_votre_token_huggingface

# MLflow (optionnel)
MLFLOW_TRACKING_URI=sqlite:///mlflow.db
```

### Obtenir votre token HF

1. CrÃ©ez un compte sur [huggingface.co](https://huggingface.co)
2. Allez dans Settings â†’ Access Tokens
3. CrÃ©ez un nouveau token
4. Collez-le dans votre `.env`

### Chargement du modÃ¨le

Le modÃ¨le se charge automatiquement de 3 sources (dans cet ordre) :

1. **Hugging Face Hub** : `PCelia/credit-scoring-model`
2. **MLflow local** : `models:/CreditScoring_LightGBM/Production`
3. **Fichier local** : `app/model.joblib`

---

## ğŸš€ Utilisation

### Lancer l'API

```bash
# Mode dÃ©veloppement
uvicorn src.api.main:app --reload

# Mode production
uvicorn src.api.main:app --host 0.0.0.0 --port 8000
```

L'API sera accessible sur `http://localhost:8000`

### AccÃ©der Ã  la documentation interactive

- **Swagger UI** : http://localhost:8000/docs
- **ReDoc** : http://localhost:8000/redoc

### Lancer le tableau de bord Streamlit

```bash
streamlit run streamlit_app.py
```

Accessible sur `http://localhost:8501`

---

## ğŸ“Š Structure des donnÃ©es

### Fichiers de donnÃ©es

| Fichier | Description | Taille |
|---------|------------|--------|
| `features_clients.csv` | CaractÃ©ristiques brutes des clients | Variable |
| `application_train_fused.csv` | DonnÃ©es d'entraÃ®nement fusionnÃ©es et nettoyÃ©es | Variable |

### Colonnes principales

Les donnÃ©es contiennent des informations sur :
- **IdentitÃ©** : SK_ID_CURR (identifiant client)
- **DonnÃ©es personnelles** : age, genre, situation familiale
- **DonnÃ©es financiÃ¨res** : revenus, dettes existantes, historique de crÃ©dit
- **DonnÃ©es professionnelles** : secteur, durÃ©e d'emploi

### Pipeline de donnÃ©es

```
DonnÃ©es brutes
    â†“
01_eda.ipynb (Exploration)
    â†“
02_fusion.ipynb (Fusion et nettoyage)
    â†“
DonnÃ©es traitÃ©es
    â†“
03_modelisation.ipynb (EntraÃ®nement LightGBM)
    â†“
ModÃ¨le ML exportÃ©
```

---

## ğŸ”Œ API REST

### Endpoints disponibles

#### 1. **PrÃ©diction (POST)**

```bash
POST /predict
Content-Type: application/json

{
  "sk_id_curr": 100001
}
```

**RÃ©ponse succÃ¨s (200)**
```json
{
  "sk_id_curr": 100001,
  "score": 0.73,
  "decision": "ACCORD",
  "probability_refusal": 0.27,
  "probability_approval": 0.73
}
```

**RÃ©ponse erreur (404)**
```json
{
  "detail": "Client not found"
}
```

#### 2. **SantÃ© de l'API (GET)**

```bash
GET /health
```

**RÃ©ponse (200)**
```json
{
  "status": "healthy"
}
```

### Exemplez d'utilisation

#### Avec `curl`

```bash
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d "{\"sk_id_curr\": 100001}"
```

#### Avec Python

```python
import requests

response = requests.post(
    "http://localhost:8000/predict",
    json={"sk_id_curr": 100001}
)
result = response.json()
print(f"Score: {result['score']}")
print(f"DÃ©cision: {result['decision']}")
```

#### Avec `httpx` (async)

```python
import httpx
import asyncio

async def get_prediction():
    async with httpx.AsyncClient() as client:
        response = await client.post(
            "http://localhost:8000/predict",
            json={"sk_id_curr": 100001}
        )
        return response.json()

asyncio.run(get_prediction())
```

### Codes HTTP

| Code | Signification |
|------|---------------|
| 200 | PrÃ©diction rÃ©ussie |
| 404 | Client non trouvÃ© |
| 422 | Format de requÃªte invalide |
| 500 | Erreur serveur |

---

## ğŸ“ˆ Monitoring et logs

### Tableau de bord Streamlit

L'application `streamlit_app.py` fournit :

- ğŸ“Š **Latence API** : Graphique en temps rÃ©el des temps de rÃ©ponse
- ğŸ“‰ **Distribution des scores** : Analyse des dÃ©cisions de crÃ©dit
- ğŸ’¾ **Historique complet** : Tous les appels enregistrÃ©s

### Format des logs

Les logs sont stockÃ©s dans `api_logs.jsonl` (JSON Lines) :

```json
{"timestamp": "2024-02-08T10:30:45", "sk_id_curr": 100001, "score": 0.73, "total_time": 0.045}
{"timestamp": "2024-02-08T10:30:50", "sk_id_curr": 100002, "score": 0.42, "total_time": 0.038}
```

### Visualiser les logs

```bash
# Voir les 10 derniÃ¨res prÃ©dictions
tail -10 api_logs.jsonl

# Convertir en CSV pour analyse
python analyze_logs.py
```

---

## ğŸ³ DÃ©ploiement

### Avec Docker (recommandÃ©)

#### 1. Construire l'image

```bash
docker build -t credit-scoring:latest .
```

#### 2. ExÃ©cuter le conteneur

```bash
docker run -p 8000:7860 \
  -e HF_TOKEN=hf_votre_token \
  credit-scoring:latest
```

#### 3. AccÃ©der Ã  l'API

```
http://localhost:8000
```

### Docker Compose

```yaml
version: '3.8'

services:
  api:
    build: .
    ports:
      - "8000:7860"
    environment:
      - HF_TOKEN=${HF_TOKEN}
    volumes:
      - ./Data:/app/Data
      - ./api_logs.jsonl:/app/api_logs.jsonl
```

Lancer avec :
```bash
docker-compose up
```

### DÃ©ploiement sur Hugging Face Spaces

Ce projet est configurÃ© pour Hugging Face Spaces (voir `README_HF.md`) :

```yaml
title: Pret A Depenser
emoji: ğŸ“‰
colorFrom: green
colorTo: indigo
sdk: docker
```

---

## ğŸ§ª Tests

### Lancer les tests

```bash
# Tous les tests
pytest

# Avec verbose
pytest -v

# Coverage
pytest --cov=src

# Test spÃ©cifique
pytest tests/test_api.py::test_prediction -v
```

### Tests disponibles

```python
# tests/test_api.py

âœ“ test_predict_valid_client()        # PrÃ©diction client valide
âœ“ test_predict_invalid_client()      # Client inexistant
âœ“ test_predict_invalid_format()      # Format JSON invalide
âœ“ test_health_check()                # VÃ©rification santÃ© API
```

### Ajouter vos propres tests

```python
# tests/test_api.py

def test_mon_test():
    """Description du test"""
    client = TestClient(app)
    response = client.post(
        "/predict",
        json={"sk_id_curr": 100001}
    )
    assert response.status_code == 200
```

---

## ğŸ“š Documentation supplÃ©mentaire

### Notebooks Jupyter

| Notebook | Description |
|----------|-------------|
| [01_eda.ipynb](notebooks/01_eda.ipynb) | Analyse exploratoire des donnÃ©es (EDA) |
| [02_fusion.ipynb](notebooks/02_fusion.ipynb) | Fusion de sources et prÃ©paration |
| [03_modelisation.ipynb](notebooks/03_modelisation.ipynb) | EntraÃ®nement et validation du modÃ¨le |

### Scripts utilitaires

```bash
# Exporter le modÃ¨le
python scripts/export_model.py

# DÃ©boguer le modÃ¨le
python debug_model.py

# Analyser les logs
python analyze_logs.py
```

### Ressources externes

- ğŸ“– [Documentation FastAPI](https://fastapi.tiangolo.com)
- ğŸ“– [Documentation LightGBM](https://lightgbm.readthedocs.io)
- ğŸ“– [Documentation Streamlit](https://docs.streamlit.io)
- ğŸ“– [Documentation MLflow](https://mlflow.org/docs)
- ğŸ“– [Hub Hugging Face](https://huggingface.co)

---

## ğŸ”§ Troubleshooting

### ProblÃ¨me : ModÃ¨le non trouvÃ©

**Erreur**
```
FileNotFoundError: Impossible de charger le modÃ¨le (ni HF Hub, ni MLflow)
```

**Solutions**
```bash
# 1. VÃ©rifier le chemin local
ls app/model.joblib

# 2. VÃ©rifier MLflow
python -c "import mlflow; print(mlflow.get_tracking_uri())"

# 3. DÃ©finir le token HF
export HF_TOKEN=your_token
# ou dans .env
echo "HF_TOKEN=your_token" > .env
```

### ProblÃ¨me : Token HF expirÃ©

**Solution**
```bash
# CrÃ©er un nouveau token sur https://huggingface.co/settings/tokens
# Mettre Ã  jour le fichier .env
nano .env  # ou edit .env
```

### ProblÃ¨me : Port dÃ©jÃ  utilisÃ©

**Erreur**
```
Address already in use: ('0.0.0.0', 8000)
```

**Solution**
```bash
# Changer le port
uvicorn src.api.main:app --port 8001

# Ou tuer le processus existant
# Windows
netstat -ano | findstr :8000
taskkill /PID <PID> /F

# Linux/Mac
lsof -ti:8000 | xargs kill -9
```

### ProblÃ¨me : Erreur LightGBM Windows

**Erreur**
```
ImportError: cannot open shared object file: No such file or directory
```

**Solution**
```bash
# RÃ©installer LightGBM
pip uninstall lightgbm -y
pip install lightgbm --force-reinstall
```

### ProblÃ¨me : Streamlit ne se lance pas

**Solution**
```bash
# VÃ©rifier les permissions
streamlit run streamlit_app.py --logger.level=debug

# RÃ©installer Streamlit
pip uninstall streamlit -y
pip install streamlit
```

---

## ğŸ‘¥ Auteurs et contribution

Ce projet a Ã©tÃ© dÃ©veloppÃ© dans le cadre d'une formation en Machine Learning.

### Structure Git

```
main                    # Branche principale (production)
â”œâ”€â”€ develop            # Branche de dÃ©veloppement
â””â”€â”€ feature/*          # Branches de fonctionnalitÃ©s
```

### Contribuer

1. CrÃ©er une branche `feature/ma-feature`
2. Faire vos commits
3. Pousser vers le repo
4. Ouvrir une Pull Request

---

## ğŸ“„ Licence

Ce projet est Ã  usage Ã©ducatif.

---

## ğŸ“ Support

Pour toute question ou problÃ¨me :
1. Consulter la section [Troubleshooting](#troubleshooting)
2. VÃ©rifier les logs : `api_logs.jsonl`
3. Lancer les tests : `pytest -v`
4. Ouvrir une issue avec les dÃ©tails

---

## âœ¨ Roadmap future

- [ ] Ajouter explication des prÃ©dictions (SHAP)
- [ ] Interface web avancÃ©e (React)
- [ ] AmÃ©liorer le monitoring (Prometheus)
- [ ] DÃ©ploiement Kubernetes
- [ ] Tests de performance
- [ ] CI/CD pipeline complet

---

**DerniÃ¨re mise Ã  jour** : FÃ©vrier 2026